# ml-inference-api
ML Inference API is a production-style machine learning deployment project that exposes trained ML models via a FastAPI-based REST service. It supports real-time predictions with confidence scores and demonstrates scalable, modular ML system design suitable for real-world applications.
